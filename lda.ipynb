{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from auxiliar_func import *\n",
    "from plot_func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Census-Income-KDD.csv')\n",
    "target = 'income_50k'\n",
    "df_tr, df_te = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting for [None, 'mode', False, 0.7, True]\n",
      "Adjusting for [None, 'mode', False, 0.8, True]\n",
      "[{'scaling': None, 'imputation': 'mode', 'cat_age': False, 'target_freq': 0.8, 'generate_dummies': True, 'remove_duplicates': True}, {'scaling': None, 'imputation': 'mode', 'cat_age': False, 'target_freq': 0.7, 'generate_dummies': True, 'remove_duplicates': True}]\n",
      "[{'solver': 'svd'}]\n",
      "Adjusting for ['svd']\n",
      "Adjusting for ['lsqr']\n",
      "Best metric: 0.753257018930653\n",
      "Best preprocessing parameters: [{'scaling': None, 'imputation': 'mode', 'cat_age': False, 'target_freq': 0.8, 'generate_dummies': True, 'remove_duplicates': True}, {'scaling': None, 'imputation': 'mode', 'cat_age': False, 'target_freq': 0.7, 'generate_dummies': True, 'remove_duplicates': True}]\n",
      "Best model parameters: [{'solver': 'svd'}, {'solver': 'lsqr'}]\n",
      "Adjusting for [None, 'mode', False, 0.7, True]\n",
      "Adjusting for [None, 'mode', False, 0.8, True]\n",
      "Adjusting for ['svd']\n",
      "Error in {'solver': 'svd'}\n",
      "Adjusting for ['lsqr']\n",
      "Error in {'solver': 'lsqr'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 78\u001b[0m\n\u001b[0;32m     73\u001b[0m lda \u001b[39m=\u001b[39m LDA(n_components\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[39m# results = test_preprocess_params(lda, prep_params_grid, df_tr, cv=2, verbose=2)\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[39m# results.head()\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m results \u001b[39m=\u001b[39m search_best_combination(lda, mod_par_grid, prep_params_grid, df_tr, target_metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mf1_macro\u001b[39;49m\u001b[39m'\u001b[39;49m, cv\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     79\u001b[0m results\u001b[39m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[16], line 58\u001b[0m, in \u001b[0;36msearch_best_combination\u001b[1;34m(model, model_params_grid, prep_params_grid, df, target_metric, cv, N, verbose)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m results \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39;49mdrop_duplicates(subset\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mprep_param\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmodel_param\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     59\u001b[0m \u001b[39mreturn\u001b[39;00m results\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39mtarget_metric, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:6532\u001b[0m, in \u001b[0;36mDataFrame.drop_duplicates\u001b[1;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6529\u001b[0m inplace \u001b[39m=\u001b[39m validate_bool_kwarg(inplace, \u001b[39m\"\u001b[39m\u001b[39minplace\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6530\u001b[0m ignore_index \u001b[39m=\u001b[39m validate_bool_kwarg(ignore_index, \u001b[39m\"\u001b[39m\u001b[39mignore_index\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 6532\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m[\u001b[39m-\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mduplicated(subset, keep\u001b[39m=\u001b[39;49mkeep)]\n\u001b[0;32m   6533\u001b[0m \u001b[39mif\u001b[39;00m ignore_index:\n\u001b[0;32m   6534\u001b[0m     result\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m default_index(\u001b[39mlen\u001b[39m(result))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:6672\u001b[0m, in \u001b[0;36mDataFrame.duplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   6670\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6671\u001b[0m     vals \u001b[39m=\u001b[39m (col\u001b[39m.\u001b[39mvalues \u001b[39mfor\u001b[39;00m name, col \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m subset)\n\u001b[1;32m-> 6672\u001b[0m     labels, shape \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(\u001b[39mlist\u001b[39m, \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(f, vals)))\n\u001b[0;32m   6674\u001b[0m     ids \u001b[39m=\u001b[39m get_group_index(\n\u001b[0;32m   6675\u001b[0m         labels,\n\u001b[0;32m   6676\u001b[0m         \u001b[39m# error: Argument 1 to \"tuple\" has incompatible type \"List[_T]\";\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6680\u001b[0m         xnull\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   6681\u001b[0m     )\n\u001b[0;32m   6682\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_sliced(duplicated(ids, keep), index\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:6640\u001b[0m, in \u001b[0;36mDataFrame.duplicated.<locals>.f\u001b[1;34m(vals)\u001b[0m\n\u001b[0;32m   6639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(vals) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[np\u001b[39m.\u001b[39mndarray, \u001b[39mint\u001b[39m]:\n\u001b[1;32m-> 6640\u001b[0m     labels, shape \u001b[39m=\u001b[39m algorithms\u001b[39m.\u001b[39;49mfactorize(vals, size_hint\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m))\n\u001b[0;32m   6641\u001b[0m     \u001b[39mreturn\u001b[39;00m labels\u001b[39m.\u001b[39mastype(\u001b[39m\"\u001b[39m\u001b[39mi8\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m), \u001b[39mlen\u001b[39m(shape)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\algorithms.py:779\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[39m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[0;32m    777\u001b[0m             values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[1;32m--> 779\u001b[0m     codes, uniques \u001b[39m=\u001b[39m factorize_array(\n\u001b[0;32m    780\u001b[0m         values,\n\u001b[0;32m    781\u001b[0m         use_na_sentinel\u001b[39m=\u001b[39;49muse_na_sentinel,\n\u001b[0;32m    782\u001b[0m         size_hint\u001b[39m=\u001b[39;49msize_hint,\n\u001b[0;32m    783\u001b[0m     )\n\u001b[0;32m    785\u001b[0m \u001b[39mif\u001b[39;00m sort \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    786\u001b[0m     uniques, codes \u001b[39m=\u001b[39m safe_sort(\n\u001b[0;32m    787\u001b[0m         uniques,\n\u001b[0;32m    788\u001b[0m         codes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    791\u001b[0m         verify\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    792\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\algorithms.py:580\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    577\u001b[0m hash_klass, values \u001b[39m=\u001b[39m _get_hashtable_algo(values)\n\u001b[0;32m    579\u001b[0m table \u001b[39m=\u001b[39m hash_klass(size_hint \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(values))\n\u001b[1;32m--> 580\u001b[0m uniques, codes \u001b[39m=\u001b[39m table\u001b[39m.\u001b[39;49mfactorize(\n\u001b[0;32m    581\u001b[0m     values,\n\u001b[0;32m    582\u001b[0m     na_sentinel\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m    583\u001b[0m     na_value\u001b[39m=\u001b[39;49mna_value,\n\u001b[0;32m    584\u001b[0m     mask\u001b[39m=\u001b[39;49mmask,\n\u001b[0;32m    585\u001b[0m     ignore_na\u001b[39m=\u001b[39;49muse_na_sentinel,\n\u001b[0;32m    586\u001b[0m )\n\u001b[0;32m    588\u001b[0m \u001b[39m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[0;32m    589\u001b[0m uniques \u001b[39m=\u001b[39m _reconstruct_data(uniques, original\u001b[39m.\u001b[39mdtype, original)\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7280\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7194\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "def search_best_combination(\n",
    "    model: object,\n",
    "    model_params_grid: dict,\n",
    "    prep_params_grid: dict,\n",
    "    df: pd.DataFrame,\n",
    "    target_metric: str = 'f1_macro',\n",
    "    cv: int = 4,\n",
    "    N: int = 5,\n",
    "    verbose: int = 1\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    best_mod_param = [{k: v[0] for k, v in model_params_grid.items()}]\n",
    "    best_prep_param = []\n",
    "\n",
    "    results = pd.DataFrame(columns=['prep_param', 'model_param',\n",
    "                           'accuracy', 'f1_macro', 'precision_macro', 'recall_macro'], dtype=object)\n",
    "\n",
    "    def update_prep_params(mod_param, prep_par_list):\n",
    "        nonlocal best_prep_param, results\n",
    "        model.set_params(**mod_param)\n",
    "        prep_par = test_preprocess_params(\n",
    "            model, prep_par_list, df, cv=cv, verbose=verbose-1).sort_values(by=target_metric, ascending=False).reset_index(drop=True)\n",
    "        prep_par['model_param'] = pd.Series([mod_param]*len(prep_par))\n",
    "        results = pd.concat([results, prep_par])\n",
    "        best_prep_param = prep_par['prep_param'][:N].tolist()\n",
    "\n",
    "    def update_mod_params(prep_param, mod_par_list):\n",
    "        nonlocal best_mod_param, results\n",
    "        mod_par = test_model_params(\n",
    "            model, mod_par_list, df, prep_param, cv=cv, verbose=verbose-1).sort_values(by=target_metric, ascending=False).reset_index(drop=True)\n",
    "        mod_par['prep_param'] = pd.Series([prep_param]*len(mod_par))\n",
    "        results = pd.concat([results, mod_par])\n",
    "        best_mod_param = mod_par['model_param'][:N].tolist()\n",
    "\n",
    "    update_prep_params(best_mod_param[0], prep_params_grid)\n",
    "    print(best_prep_param)\n",
    "    print(best_mod_param)\n",
    "\n",
    "    update_mod_params(best_prep_param[0], model_params_grid)\n",
    "\n",
    "    best_metric = results[target_metric].max()\n",
    "\n",
    "    while True:\n",
    "        if verbose > 0:\n",
    "            print(f\"Best metric: {best_metric}\")\n",
    "        if verbose > 0:\n",
    "            print(f\"Best preprocessing parameters: {best_prep_param}\")\n",
    "        if verbose > 0:\n",
    "            print(f\"Best model parameters: {best_mod_param}\")\n",
    "\n",
    "        update_prep_params(best_mod_param[0], prep_params_grid)\n",
    "        update_mod_params(best_prep_param, model_params_grid)\n",
    "        if results[target_metric].max() > best_metric:\n",
    "            best_metric = results[target_metric].max()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Convert dictionaries to string representations\n",
    "    results['column_name_str'] = results['column_name'].astype(str)\n",
    "\n",
    "    # Remove duplicates based on the string representation of the column\n",
    "    results = results.drop_duplicates(subset='column_name_str')\n",
    "\n",
    "    # Remove the temporary string representation column\n",
    "    results = results.drop('column_name_str', axis=1)\n",
    "\n",
    "    return results.sort_values(by=target_metric, ascending=False).reset_index(drop=True)\n",
    "\n",
    "prep_params_grid = {\n",
    "    'scaling': [None],\n",
    "    'imputation': ['mode'],\n",
    "    'cat_age': [False],\n",
    "    'target_freq': [0.7, 0.8],\n",
    "    'generate_dummies': [True]\n",
    "}\n",
    "\n",
    "mod_par_grid = {\n",
    "    'solver': ['svd', 'lsqr']\n",
    "}\n",
    "\n",
    "lda = LDA(n_components=1)\n",
    "\n",
    "# results = test_preprocess_params(lda, prep_params_grid, df_tr, cv=2, verbose=2)\n",
    "# results.head()\n",
    "\n",
    "results = search_best_combination(lda, mod_par_grid, prep_params_grid, df_tr, target_metric='f1_macro', cv=2, verbose=1)\n",
    "results.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
