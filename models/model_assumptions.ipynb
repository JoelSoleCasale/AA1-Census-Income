{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from auxiliar_func import *\n",
    "from plot_func import *\n",
    "import os\n",
    "from sklearn.covariance import EmpiricalCovariance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to check if the assumptions made by the models are satisfied by our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'income_50k'               # target variable\n",
    "df_tr = pd.read_csv('../train.csv') # training set\n",
    "\n",
    "TARGET_METRIC = 'f1_macro'          # metric to be used in the grid search\n",
    "SEED = 42                           # seed for reproducibility"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum value of both covariance matrices is: 9.796603255272977\n",
      "The maximum difference between the covariance matrices is: 9.605063550677642\n",
      "The minimum difference between the covariance matrices is: 0.0\n",
      "Covariance matrices are equal with a delta error of 0.1: False\n"
     ]
    }
   ],
   "source": [
    "preprocessing_params = {}\n",
    "if os.path.exists('./results/results_lda.csv'):\n",
    "    preprocessing_params, _ = get_best_params('results/results_lda.csv')\n",
    "\n",
    "preproc_lda = preprocessing(df_tr, **preprocessing_params)\n",
    "\n",
    "cov1 = EmpiricalCovariance().fit(preproc_lda[preproc_lda[target] == 0].drop(columns=target)).covariance_\n",
    "cov2 = EmpiricalCovariance().fit(preproc_lda[preproc_lda[target] == 1].drop(columns=target)).covariance_\n",
    "\n",
    "print(\"The maximum value of both covariance matrices is:\", max(np.max(np.abs(cov1)), np.max(np.abs(cov2))))\n",
    "print(\"The maximum difference between the covariance matrices is:\", np.max(np.abs(cov1 - cov2)))\n",
    "print(\"The minimum difference between the covariance matrices is:\", np.min(np.abs(cov1 - cov2)))\n",
    "\n",
    "print('Covariance matrices are equal with a delta error of 0.1:', np.allclose(cov1, cov2, atol=0.1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_params = {}\n",
    "if os.path.exists('./results/results_logreg.csv'):\n",
    "    preprocessing_params, _ = get_best_params('results/results_logreg.csv')\n",
    "\n",
    "preproc_logreg = preprocessing(df_tr, **preprocessing_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It assumes that there is minimal or no multicolinearity among the independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VIF Factor         features\n",
      "0    1.028530    wage_per_hour\n",
      "1    1.024095    capital_gains\n",
      "2    1.011231   capital_losses\n",
      "3    1.017368  stock_dividends\n",
      "4    1.857902          num_emp\n",
      "5    1.872220     weeks_worked\n"
     ]
    }
   ],
   "source": [
    "# get only numerical columns\n",
    "preproc_logreg_numerical = preproc_logreg.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# calculate VIF for each feature\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(preproc_logreg_numerical.values, i) for i in range(preproc_logreg_numerical.shape[1])]\n",
    "vif[\"features\"] = preproc_logreg_numerical.columns\n",
    "\n",
    "print(vif)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It usually requires a larga sample size to predict properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58633, 483)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_logreg.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It assumes independent observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are duplicated rows: True\n"
     ]
    }
   ],
   "source": [
    "# check if there are duplicated rows\n",
    "print('There are duplicated rows:', preproc_logreg.duplicated().any())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_params = {}\n",
    "if os.path.exists('./results/results_knn.csv'):\n",
    "    preprocessing_params, _ = get_best_params('results/results_knn.csv')\n",
    "\n",
    "preproc_knn = preprocessing(df_tr, **preprocessing_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is in feature space, which means data in feature space can be measured by distance metrics such as Manhattan, Euclidean, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distances between all points (there are categorical features)\n",
    "from scipy.spatial.distance import pdist\n",
    "distances = pdist(preproc_knn.drop(columns=target), metric='hamming')\n",
    "print(distances[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the training data points consists of a set of vectors and a class label associated with each vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print random observation\n",
    "print(preproc_knn.iloc[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
