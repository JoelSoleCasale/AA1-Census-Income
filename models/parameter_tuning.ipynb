{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "# Importing the models to be tested\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from auxiliar_func import *\n",
    "from plot_func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model combinations to be tested: 72\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Census-Income-KDD.csv')\n",
    "target = 'income_50k'\n",
    "df_tr, df_te = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "TARGET_METRIC = 'f1_macro'\n",
    "SEED = 42\n",
    "\n",
    "prep_params_grid = {\n",
    "    'scaling': [None, 'minmax', 'standard'],\n",
    "    'imputation': ['mode'],\n",
    "    'cat_age': [False, True],\n",
    "    'merge_capital': [False, True],\n",
    "    'downsampling_method': ['random', 'NearMiss'],\n",
    "    'target_freq': [0.75, 0.8, 0.85],\n",
    "    'generate_dummies': [True]\n",
    "}\n",
    "\n",
    "def n_comb(grid: dict, print_=True):\n",
    "    n = 1\n",
    "    for k in grid.keys():\n",
    "        n *= len(grid[k])\n",
    "    if print_:\n",
    "        print(f'Number of model combinations to be tested: {n}')\n",
    "    else:\n",
    "        return n\n",
    "\n",
    "def test_model(mod, prep_grid, mod_grid, name):\n",
    "    if not os.path.exists(f'results_{name}.csv'):\n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\") # to avoid convergence warnings\n",
    "                results = search_best_combination(mod, mod_grid, prep_grid, df_tr, target_metric=TARGET_METRIC)\n",
    "                results.to_csv(f'results_{name}.csv', index=False)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "    \n",
    "n_comb(prep_params_grid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning parameters for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model combinations to be tested: 36\n",
      "===Iteration 1===\n",
      "Searching preprocessing parameters...\n",
      "it: 72/72\n",
      "Searching model parameters...\n",
      "it: 36/36\n",
      "Best metric: 0.7581762636547423\n",
      "Best preprocessing parameters: [{'scaling': 'standard', 'imputation': 'mode', 'cat_age': True, 'merge_capital': False, 'downsampling_method': 'random', 'target_freq': 0.85, 'generate_dummies': True, 'remove_duplicates': True}, {'scaling': None, 'imputation': 'mode', 'cat_age': True, 'merge_capital': False, 'downsampling_method': 'random', 'target_freq': 0.85, 'generate_dummies': True, 'remove_duplicates': True}, {'scaling': 'minmax', 'imputation': 'mode', 'cat_age': True, 'merge_capital': False, 'downsampling_method': 'random', 'target_freq': 0.85, 'generate_dummies': True, 'remove_duplicates': True}, {'scaling': 'minmax', 'imputation': 'mode', 'cat_age': False, 'merge_capital': False, 'downsampling_method': 'random', 'target_freq': 0.85, 'generate_dummies': True, 'remove_duplicates': True}, {'scaling': None, 'imputation': 'mode', 'cat_age': True, 'merge_capital': False, 'downsampling_method': 'random', 'target_freq': 0.8, 'generate_dummies': True, 'remove_duplicates': True}, {'scaling': None, 'imputation': 'mode', 'cat_age': False, 'merge_capital': False, 'downsampling_method': 'random', 'target_freq': 0.85, 'generate_dummies': True, 'remove_duplicates': True}, {'scaling': 'minmax', 'imputation': 'mode', 'cat_age': True, 'merge_capital': True, 'downsampling_method': 'random', 'target_freq': 0.85, 'generate_dummies': True, 'remove_duplicates': True}, {'scaling': None, 'imputation': 'mode', 'cat_age': True, 'merge_capital': True, 'downsampling_method': 'random', 'target_freq': 0.85, 'generate_dummies': True, 'remove_duplicates': True}, {'scaling': 'standard', 'imputation': 'mode', 'cat_age': True, 'merge_capital': True, 'downsampling_method': 'random', 'target_freq': 0.85, 'generate_dummies': True, 'remove_duplicates': True}, {'scaling': 'minmax', 'imputation': 'mode', 'cat_age': True, 'merge_capital': False, 'downsampling_method': 'random', 'target_freq': 0.8, 'generate_dummies': True, 'remove_duplicates': True}]\n",
      "Best model parameters: [{'solver': 'svd', 'shrinkage': None, 'store_covariance': True, 'tol': 0.0001}, {'solver': 'lsqr', 'shrinkage': None, 'store_covariance': False, 'tol': 0.01}, {'solver': 'svd', 'shrinkage': None, 'store_covariance': True, 'tol': 0.01}, {'solver': 'eigen', 'shrinkage': 'auto', 'store_covariance': True, 'tol': 0.001}, {'solver': 'svd', 'shrinkage': None, 'store_covariance': True, 'tol': 0.001}, {'solver': 'svd', 'shrinkage': None, 'store_covariance': False, 'tol': 0.0001}, {'solver': 'lsqr', 'shrinkage': None, 'store_covariance': False, 'tol': 0.0001}, {'solver': 'lsqr', 'shrinkage': 'auto', 'store_covariance': False, 'tol': 0.01}, {'solver': 'eigen', 'shrinkage': 'auto', 'store_covariance': False, 'tol': 0.0001}, {'solver': 'lsqr', 'shrinkage': None, 'store_covariance': True, 'tol': 0.001}]\n",
      "===Iteration 2===\n",
      "Searching preprocessing parameters...\n",
      "\n",
      "Searching model parameters...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod_par_grid = {\n",
    "    'solver': ['svd', 'lsqr', 'eigen'],\n",
    "    'shrinkage': [None, 'auto'],\n",
    "    'store_covariance': [True, False],\n",
    "    'tol': [1e-4, 1e-3, 1e-2],\n",
    "}\n",
    "\n",
    "n_comb(mod_par_grid)\n",
    "\n",
    "lda = LDA()\n",
    "test_model(lda, prep_params_grid, mod_par_grid, 'lda')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning parameters for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model combinations to be tested: 144\n",
      "===Iteration 1===\n",
      "Searching preprocessing parameters...\n",
      "it: 27/72\r"
     ]
    }
   ],
   "source": [
    "mod_par_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'fit_intercept': [True, False],\n",
    "    'intercept_scaling': [0.1, 1, 10],\n",
    "    'max_iter': [1000],\n",
    "    'multi_class': ['auto'],\n",
    "    'random_state': [SEED],\n",
    "    'solver': ['saga'],\n",
    "    'n_jobs': [-1],\n",
    "}\n",
    "\n",
    "n_comb(mod_par_grid)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "test_model(logreg, prep_params_grid, mod_par_grid, 'logreg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning parameters for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_par_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['squared_hinge','hinge'],\n",
    "    'dual': [False],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'fit_intercept': [True, False],\n",
    "    'intercept_scaling': [0.1, 1],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'max_iter': [1000],\n",
    "    'random_state': [SEED]\n",
    "}\n",
    "\n",
    "n_comb(mod_par_grid)\n",
    "\n",
    "svm = LinearSVC()\n",
    "test_model(svm, prep_params_grid, mod_par_grid, 'svm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning parameters for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_par_grid = {\n",
    "    'n_estimators': [50, 75, 100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 20, 25, 30],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'random_state': [SEED],\n",
    "    'verbose': [0],\n",
    "    'warm_start': [False],\n",
    "    'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "n_comb(mod_par_grid)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "test_model(rf, prep_params_grid, mod_par_grid, 'rf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning parameters for catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_params_grid2 = {\n",
    "    'scaling': [None],\n",
    "    'imputation': ['mode'],\n",
    "    'cat_age': [False],\n",
    "    'merge_capital': [False, True],\n",
    "    'downsampling_method': ['random', 'NearMiss'],\n",
    "    'target_freq': [0.75, 0.8, 0.85],\n",
    "    'generate_dummies': [False]\n",
    "}\n",
    "\n",
    "# a first preprocess to get the categorical features\n",
    "df_tr_pre = preprocessing(df_tr, imputation='mode', cat_age=False, generate_dummies=False)\n",
    "X_train, y_train = df_tr_pre.drop(target, axis=1), df_tr_pre[target]\n",
    "cat_features = list(X_train.select_dtypes(include=['category']).columns)\n",
    "\n",
    "mod_par_grid = {\n",
    "    'iterations': [5],\n",
    "    'depth': [6, 8, 10],\n",
    "    'border_count': [32, 64, 128],\n",
    "    'random_seed': [SEED],\n",
    "    'verbose': [0],\n",
    "    'loss_function': ['Logloss'],\n",
    "    'eval_metric': ['F1', 'AUC'],\n",
    "    'class_weights': [[1, 1], [1, 2], [1, 3]],\n",
    "    'cat_features': [cat_features],\n",
    "}\n",
    "\n",
    "n_comb(mod_par_grid)\n",
    "\n",
    "cat_model = CatBoostClassifier()\n",
    "test_model(cat_model, prep_params_grid2, mod_par_grid, 'catboost')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
